{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOh7qfQ+vE+/xDB5PV7Cj4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekMangal/Ai-projects/blob/main/PipeLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMoYmuxsRR5x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_sales_number = [21,22,-108, 31, -1,32,34,31]"
      ],
      "metadata": {
        "id": "jpiuCu-3RkAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_number)\n",
        "tf_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmNmcE87RwSe",
        "outputId": "b4a32946-3950-44f2-c880-f421cc5590bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sales in tf_dataset:\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au8SNDLVR6VA",
        "outputId": "ad050d29-974f-43b5-8317-e0d6405533e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "22\n",
            "-108\n",
            "31\n",
            "-1\n",
            "32\n",
            "34\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for slaes in tf_dataset.take(3):\n",
        "  print(sales.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfaeeMliSAyB",
        "outputId": "705b3310-e878-4b7d-8425-ac2fed4c79b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "31\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
        "for sales in tf_dataset.as_numpy_iterator():\n",
        "  print(sales)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGg1wyvZSMcj",
        "outputId": "2fbb590e-7e7d-4f85-d4a4-bd5822431358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "22\n",
            "31\n",
            "32\n",
            "34\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf_dataset.map(lambda x: x*72)"
      ],
      "metadata": {
        "id": "5o-kNl0dSbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf_dataset.shuffle(3)\n",
        "for sales in tf_dataset.as_numpy_iterator():\n",
        "  print(sales)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFD__NyDSiZt",
        "outputId": "7a040b94-d55b-44af-92f5-f5282e268ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1584\n",
            "1512\n",
            "2232\n",
            "2232\n",
            "2448\n",
            "2304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tlYUdy7JS9Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sales_batch in tf_dataset.batch(3):\n",
        "  print(sales_batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89iIaFpCS2cb",
        "outputId": "5c04c613-c050-4e18-e4a9-ae0060dc26c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1512 2232 1584]\n",
            "[2304 2448 2232]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "can be possible to all these thing in one line"
      ],
      "metadata": {
        "id": "vH1MwbhpTAmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zCd0wkx5TAYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_number)\n",
        "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(2).batch(2)"
      ],
      "metadata": {
        "id": "FIWgwJRgS7V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sale in tf_dataset.as_numpy_iterator():\n",
        "  print(sale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJM3VOkwTLek",
        "outputId": "24bb1464-4acd-436e-de96-5a5a4f8bc169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1512 2232]\n",
            "[1584 2448]\n",
            "[2232 2304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=True)\n",
        "for file in images_ds.take(5):\n",
        "  print(file.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "WWUUo0fcTMZk",
        "outputId": "1c97a8e5-c042-4712-e114-e6e9b735f770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: images/*/*'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2963174939>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/*/*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           string_ops.reduce_join(file_pattern, separator=\", \"), name=\"message\")\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m       assert_not_empty = control_flow_assert.Assert(\n\u001b[0m\u001b[1;32m   1330\u001b[0m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[1;32m   1331\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/control_flow_assert.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdata_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_summarize_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[1;32m    103\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: images/*/*'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"cat\", \"dog\"]"
      ],
      "metadata": {
        "id": "yqwhvSgnVBlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(images_ds)"
      ],
      "metadata": {
        "id": "Y_iyHgbdWRiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(image_count*0.8)\n",
        "train_ds = images_ds.take(train_size)\n",
        "test_ds = images_ds.skip(train_size)"
      ],
      "metadata": {
        "id": "M0Oeo7SOWV-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fAiND-vMYrUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_labels(file_path):\n",
        "\n",
        "  file_path_str = tf.strings.split(file_path, os.sep)\n",
        "\n",
        "  return file_path_str[-2]"
      ],
      "metadata": {
        "id": "MAExi8CMWt2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_image(file_path):\n",
        "    label = get_labels(file_path)\n",
        "    img = tf.io.read_file(file_path) # load the raw data from the file as a string\n",
        "    img = tf.image.decode_jpeg(img)\n",
        "    img = tf.image.resize(img, [128, 128])\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "kQQqBhlaZclM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in train_ds.map(process_image):\n",
        "    print(img)\n",
        "    print(label)"
      ],
      "metadata": {
        "id": "nrRxjfQiZDr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = train_ds.map(process_image)\n",
        "test_ds = test_ds.map(process_image)"
      ],
      "metadata": {
        "id": "YWLvO5fKXFLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"****\",image)\n",
        "    print(\"****\",label)"
      ],
      "metadata": {
        "id": "sLA2n26rXLH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ebd014"
      },
      "source": [
        "\n",
        "def scale(image, label):\n",
        "    return image/255, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = train_ds.map(scale)"
      ],
      "metadata": {
        "id": "sLeovo1QYFPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for image, label in train_ds.take(5):\n",
        "    print(\"****Image: \",image.numpy()[0][0])\n",
        "    print(\"****Label: \",label.numpy())\n"
      ],
      "metadata": {
        "id": "usIcg6HQbxrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b2f95ec"
      },
      "source": [
        "import os\n",
        "os.makedirs('images/cat', exist_ok=True)\n",
        "os.makedirs('images/dog', exist_ok=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete .ipynb checkpoints from cat dir\n",
        "\n",
        "!rm -rf images/cat/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "up0lYjngU-xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FeKcypGxVS03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}